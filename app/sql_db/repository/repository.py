import csv

from sqlalchemy import create_engine
from sqlalchemy.exc import SQLAlchemyError
from sqlalchemy.orm import sessionmaker
import numpy as np

from app.settings.sql_config import SQL_URL
from app.sql_db.database import session_maker, engine
from app.sql_db.models.buisness_owner import BusinessOwner
from app.sql_db.models.category import Category
from app.sql_db.models.smb import Smb
from app.sql_db.models.smb_category import SmbCategory
from app.sql_db.models.transaction import Transaction
from app.sql_db.models.xtribution import Xtribution
import pandas as pd
from sqlalchemy import text

#here we will werite all the SQL queries


def mysweetarithatilovesomuchhhhhhhhhhhh():
    with session_maker() as session:
        print(len(session.query(SmbCategory).all()))
        # session.execute(text('DROP TABLE transactions CASCADE;'))
        # session.commit()
        # smbs = session.query(Xtribution).all()
        #
        # if not smbs:
        #     print("×œ× × ××¦××• × ×ª×•× ×™× ×‘×˜×‘×œ×” Smb.")
        #     return
        #
        # # ×”××¨×” ×œ×¨×©×™××ª ××™×œ×•× ×™×
        # data = [
        #     {column.name: getattr(smb, column.name) for column in Xtribution.__table__.columns}
        #     for smb in smbs
        # ]
        #
        # # ×”××¨×” ×œÖ¾DataFrame
        # df = pd.DataFrame(data)
        #
        # # ×©××™×¨×” ×œÖ¾CSV ×‘×œ×™ ××™× ×“×§×¡ ××™×•×ª×¨
        # df.to_csv('xtribution.csv', index=False, encoding='utf-8')
        #
        # print(f"×”× ×ª×•× ×™× × ×©××¨×• ×‘×”×¦×œ×—×” ×‘×§×•×‘×¥: ")
        #

mysweetarithatilovesomuchhhhhhhhhhhh()




def import_csv_to_transactions(csv_path: str, max_rows: int = 40000):
    df = pd.read_csv(csv_path, encoding='utf-8', nrows=max_rows)

    # ×©××™×¨×” ×¨×§ ×¢×œ ×¢××•×“×•×ª ×©×¨×œ×•×•× ×˜×™×•×ª ×œ××•×“×œ
    valid_columns = Transaction.__table__.columns.keys()
    df = df[[col for col in df.columns if col in valid_columns]]

    # ×”××¨×ª NaN ×œÖ¾None
    df = df.replace({np.nan: None})

    successful_inserts = 0
    failed_rows = []

    with session_maker() as session:
        for index, row in df.iterrows():
            try:
                # ×”××¨×ª float ×œÖ¾int ×× ×”×¢×¨×š ×××•×¨ ×œ×”×™×•×ª ××¡×¤×¨ ×©×œ×
                row_data = {
                    k: int(v) if isinstance(v, float) and v.is_integer() else v
                    for k, v in row.to_dict().items()
                }

                transaction = Transaction(**row_data)
                session.add(transaction)
                successful_inserts += 1

            except Exception as e:
                failed_rows.append((index + 1, str(e)))

        # × ×™×¡×™×•×Ÿ ×œ×‘×¦×¢ commit ×›×•×œ×œ
        try:
            session.commit()
            print(f"×”×•×–× ×• ×‘×”×¦×œ×—×” {successful_inserts} ×¨×©×•××•×ª ××”×§×•×‘×¥ {csv_path}")
        except SQLAlchemyError as e:
            session.rollback()
            print("âŒ ×©×’×™××” ×‘Ö¾commit ×”×¡×•×¤×™:")
            print(str(e))

    # ×¡×™×›×•×
    if failed_rows:
        print(f"\nğŸ’¥ {len(failed_rows)} ×©×•×¨×•×ª × ×›×©×œ×•:")
        for i, err in failed_rows[:10]:  # ××“×¤×™×¡ ×¨×§ ××ª 10 ×”×¨××©×•× ×•×ª
            print(f"×©×•×¨×” {i}: {err}")

# ×§×¨×™××” ×œ×¤×•× ×§×¦×™×”
# import_csv_to_transactions('transaction.csv')

def check_problematic_rows_for_db(csv_path: str, max_rows: int = 20000):
    df = pd.read_csv(csv_path, encoding='utf-8', nrows=max_rows)

    # ×©××™×¨×” ×¨×§ ×¢×œ ×¢××•×“×•×ª ×©×¨×œ×•×•× ×˜×™×•×ª ×œ××•×“×œ
    valid_columns = Transaction.__table__.columns.keys()
    df = df[[col for col in df.columns if col in valid_columns]]

    print(f"ğŸ“„ ×‘×•×“×§ ××ª {len(df)} ×”×©×•×¨×•×ª ×”×¨××©×•× ×•×ª ×‘×§×•×‘×¥ {csv_path}...")

    problematic_rows = []

    with session_maker() as session:
        for index, row in df.iterrows():
            try:
                transaction = Transaction(**row.to_dict())
                session.add(transaction)
                session.flush()  # × × ×¡×” ×œ×›×ª×•×‘ ×œ××¡×“ ××š ×‘×œ×™ ×œ×‘×¦×¢ commit
                session.rollback()
            except SQLAlchemyError as e:
                problematic_rows.append((index + 1, row.to_dict(), str(e)))
                session.rollback()

    if problematic_rows:
        print(f"\nğŸ” × ××¦××• {len(problematic_rows)} ×©×•×¨×•×ª ×‘×¢×™×™×ª×™×•×ª ××ª×•×š {len(df)} ×©×•×¨×•×ª ×©× ×‘×“×§×•:\n")
        for idx, row_data, error in problematic_rows:
            print(f"×©×•×¨×” {idx}: âŒ ×©×’×™××”: {error}")
            print(f"  â¤ ×ª×•×›×Ÿ ×”×©×•×¨×”: {row_data}\n")
    else:
        print(f"\nâœ… ×œ× × ××¦××• ×©×•×¨×•×ª ×‘×¢×™×™×ª×™×•×ª. ×›×œ {len(df)} ×”×©×•×¨×•×ª × ×¨××•×ª ×ª×§×™× ×•×ª ×œ×”×›× ×¡×” ×œ××¡×“ ×”× ×ª×•× ×™×.")

# ×§×¨×™××” ×œ×“×•×’××”
# check_problematic_rows_for_db('transaction.csv', max_rows=40000)
def da():
    df = pd.read_sql("SELECT create_date, SMB_ID, XTRIBUTER_ID FROM transactions", engine.connect())

    # ×”××¨×” ×œ-UTC ×›×“×™ ×œ×”×™×× ×¢ ××‘×¢×™×•×ª timezone
    df['create_date'] = pd.to_datetime(df['create_date'], utc=True)

    first_purchase = (
        df.groupby(['smb_id', 'xtributer_id'])['create_date']
        .min()
        .reset_index()
        .rename(columns={'create_date': 'first_date'})
    )
    # ×’× ×›××Ÿ, ×œ×•×•×“× ×©-first_date ×‘-UTC
    first_purchase['first_date'] = pd.to_datetime(first_purchase['first_date'], utc=True)

    df = df.merge(first_purchase, on=['smb_id', 'xtributer_id'], how='left')

    df['customer_status'] = df.apply(
        lambda row: 'new' if row['create_date'] == row['first_date'] else 'returning',
        axis=1
    )

    df['month'] = df['create_date'].dt.to_period('M')

    summary = (
        df.groupby(['month', 'smb_id', 'customer_status'])['xtributer_id']
        .nunique()
        .reset_index()
        .rename(columns={'xtributer_id': 'num_customers'})
    )

    summary['month'] = summary['month'].dt.to_timestamp()

    print(summary)



# da()